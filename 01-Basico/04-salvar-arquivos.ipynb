{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/03 06:14:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_estabelecimento = '/home/rafael/Downloads/estabelecimentos/'\n",
    "estabelecimento = spark.read.csv(path_estabelecimento, sep=';', inferSchema=True)\n",
    "\n",
    "\n",
    "path_empresas = '/home/rafael/Downloads/socios/'\n",
    "empresas = spark.read.csv(path_empresas, sep=';', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estabsColNames = ['cnpj_basico', 'cnpj_ordem', 'cnpj_dv', 'identificador_matriz_filial', 'nome_fantasia', 'situacao_cadastral', 'data_situacao_cadastral', 'motivo_situacao_cadastral', 'nome_da_cidade_no_exterior', 'pais', 'data_de_inicio_atividade', 'cnae_fiscal_principal', 'cnae_fiscal_secundaria', 'tipo_de_logradouro', 'logradouro', 'numero', 'complemento', 'bairro', 'cep', 'uf', 'municipio', 'ddd_1', 'telefone_1', 'ddd_2', 'telefone_2', 'ddd_do_fax', 'fax', 'correio_eletronico', 'situacao_especial', 'data_da_situacao_especial']\n",
    "\n",
    "empresasColNames = ['cnpj_basico', 'identificador_de_socio', 'nome_do_socio_ou_razao_social', 'cnpj_ou_cpf_do_socio', 'qualificacao_do_socio', 'data_de_entrada_sociedade', 'pais', 'representante_legal', 'nome_do_representante', 'qualificacao_do_representante_legal', 'faixa_etaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, colName in enumerate(empresasColNames):\n",
    "    empresas = empresas.withColumnRenamed(f\"_c{index}\", colName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, colName in enumerate(estabsColNames):\n",
    "    estabelecimento = estabelecimento.withColumnRenamed(f\"_c{index}\", colName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "empresas = empresas.withColumn('qualificacao_do_socio', f.regexp_replace('qualificacao_do_socio',',','.'))\n",
    "empresas = empresas.withColumn('qualificacao_do_socio', empresas['qualificacao_do_socio'].cast(DoubleType()))\n",
    "empresas = empresas.withColumn(\"data_de_entrada_sociedade\", f.to_date(empresas.data_de_entrada_sociedade.cast(StringType()),'yyyyMMdd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empresas.write.csv(path='csv',mode='overwrite',sep=';',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empresas2 = spark.read.csv('csv',sep=';',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cnpj_basico: integer (nullable = true)\n",
      " |-- identificador_de_socio: integer (nullable = true)\n",
      " |-- nome_do_socio_ou_razao_social: string (nullable = true)\n",
      " |-- cnpj_ou_cpf_do_socio: string (nullable = true)\n",
      " |-- qualificacao_do_socio: double (nullable = true)\n",
      " |-- data_de_entrada_sociedade: date (nullable = true)\n",
      " |-- pais: integer (nullable = true)\n",
      " |-- representante_legal: string (nullable = true)\n",
      " |-- nome_do_representante: string (nullable = true)\n",
      " |-- qualificacao_do_representante_legal: integer (nullable = true)\n",
      " |-- faixa_etaria: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empresas2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/03 06:14:36 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/02/03 06:14:36 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/02/03 06:14:36 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "24/02/03 06:14:38 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "24/02/03 06:14:38 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empresas.write.parquet(path='parquet',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "empresas_parquet = spark.read.parquet('parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cnpj_basico: integer (nullable = true)\n",
      " |-- identificador_de_socio: integer (nullable = true)\n",
      " |-- nome_do_socio_ou_razao_social: string (nullable = true)\n",
      " |-- cnpj_ou_cpf_do_socio: string (nullable = true)\n",
      " |-- qualificacao_do_socio: double (nullable = true)\n",
      " |-- data_de_entrada_sociedade: date (nullable = true)\n",
      " |-- pais: integer (nullable = true)\n",
      " |-- representante_legal: string (nullable = true)\n",
      " |-- nome_do_representante: string (nullable = true)\n",
      " |-- qualificacao_do_representante_legal: integer (nullable = true)\n",
      " |-- faixa_etaria: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empresas_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particionamento de Dados\n",
    "\n",
    "Salva com menos partições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empresas.coalesce(1).write.csv(path='csv-unico',mode='overwrite',sep=';',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salva em pastas separadas de acordo com o parttionBy, demora bastante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empresas.write.parquet(path='parquet-unico',mode='overwrite',partitionBy='cnpj_basico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
